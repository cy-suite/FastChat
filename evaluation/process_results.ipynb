{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_qa_samples = {}\n",
    "model_names = [\"gpt-4o-mini\", \"gpt-4o\", \"claude-3.5-sonnet\", \"gemini-v1.5-flash\",\n",
    "               \"geminipro\", \"nvidia-llama31-70\", \"nvidia-llama31-405\"]\n",
    "for model_name in model_names:        \n",
    "    simple_qa_samples[model_name+\"-agent\"] = pd.read_json(\"eval_samples/simple_qa_250_{}-agent.jsonl\".format(model_name), lines=True)\n",
    "    if model_name == \"claude-3.5-sonnet\":\n",
    "        simple_qa_samples[model_name+\"-agent\"] = simple_qa_samples[model_name+\"-agent\"].iloc[:120]\n",
    "\n",
    "simple_qa_samples['gemini-v1.5-flash-agent'] = pd.read_json(\"eval_samples/simple_qa_250-gemini-v1.5-flash-agent-ablation.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-mini-agent': 0.784,\n",
       " 'gpt-4o-agent': 0.78,\n",
       " 'claude-3.5-sonnet-agent': 0.8916666666666667,\n",
       " 'gemini-v1.5-flash-agent': 0.628,\n",
       " 'geminipro-agent': 0.8113207547169812,\n",
       " 'nvidia-llama31-70-agent': 0.624,\n",
       " 'nvidia-llama31-405-agent': 0.264}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search_invoked = {}\n",
    "for model_name in simple_qa_samples.keys():\n",
    "    web_search_invoked[model_name] = float((simple_qa_samples[model_name][\"search_done\"]).mean())\n",
    "web_search_invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_qa_results = {}\n",
    "model_names = [\"gpt-4o-mini\", \"gpt-4o\", \"claude-3.5-sonnet\", \"gemini-v1.5-flash\",\n",
    "               \"geminipro\", \"nvidia-llama31-70\", \"nvidia-llama31-405\"]\n",
    "for model_name in model_names:\n",
    "    simple_qa_results[model_name] = pd.read_json(\"eval_results/simple_qa_250_{}_results.jsonl\".format(model_name), lines=True)\n",
    "    if model_name == \"claude-3.5-sonnet\":\n",
    "        simple_qa_results[model_name] = simple_qa_results[model_name].iloc[:120]\n",
    "for model_name in model_names:\n",
    "    simple_qa_results[model_name+\"-agent\"] = pd.read_json(\"eval_results/simple_qa_250_{}-agent_results.jsonl\".format(model_name), lines=True)\n",
    "    if model_name == \"claude-3.5-sonnet\":\n",
    "        simple_qa_results[model_name+\"-agent\"] = simple_qa_results[model_name+\"-agent\"].iloc[:120]\n",
    "\n",
    "simple_qa_results[\"gemini-v1.5-flash-agent\"] = pd.read_json(\"eval_results/simple_qa_250-gemini-v1.5-flash-agent-ablation_results.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-mini': 0.1,\n",
       " 'gpt-4o': 0.44,\n",
       " 'claude-3.5-sonnet': 0.2916666666666667,\n",
       " 'gemini-v1.5-flash': 0.112,\n",
       " 'geminipro': 0.2459016393442623,\n",
       " 'nvidia-llama31-70': 0.152,\n",
       " 'nvidia-llama31-405': 0.188,\n",
       " 'gpt-4o-mini-agent': 0.588,\n",
       " 'gpt-4o-agent': 0.72,\n",
       " 'claude-3.5-sonnet-agent': 0.7166666666666667,\n",
       " 'gemini-v1.5-flash-agent': 0.4,\n",
       " 'geminipro-agent': 0.6415094339622641,\n",
       " 'nvidia-llama31-70-agent': 0.488,\n",
       " 'nvidia-llama31-405-agent': 0.436}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = {}\n",
    "for model_name in simple_qa_results.keys():\n",
    "    model_accuracy = float((simple_qa_results[model_name][\"grade\"] == \"A\").mean())\n",
    "    accuracy[model_name] = model_accuracy\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_hard_samples = {}\n",
    "for model_name in [\"gpt-4o\", \"nvidia-llama31\"]:\n",
    "    arena_hard_samples[model_name+\"-agent\"] = pd.read_json(\"eval_samples/arena_hard_50_{}-agent.jsonl\".format(model_name), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-agent': 0.08, 'nvidia-llama31-agent': 0.22}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search_invoked_arena = {}\n",
    "for model_name in arena_hard_samples.keys():\n",
    "    web_search_invoked_arena[model_name] = float((arena_hard_samples[model_name][\"search_done\"]).mean())\n",
    "web_search_invoked_arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_hard_results = {}\n",
    "for model_name in [\"gpt-4o\", \"llama31\"]:\n",
    "    arena_hard_results[model_name] = pd.read_json(\"eval_results/arena_hard_{}.jsonl\".format(model_name), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': 0.46, 'llama31': 0.4}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrate = {}\n",
    "for model_name in arena_hard_results.keys():\n",
    "    model_winrate = float((arena_hard_results[model_name][\"grade\"] == \"agent\").mean())\n",
    "    winrate[model_name] = model_winrate\n",
    "winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': 0.54, 'llama31': 0.6}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrate = {}\n",
    "for model_name in arena_hard_results.keys():\n",
    "    model_winrate = float((arena_hard_results[model_name][\"grade\"] == \"base\").mean())\n",
    "    winrate[model_name] = model_winrate\n",
    "winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
